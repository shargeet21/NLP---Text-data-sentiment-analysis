{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sharg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Task 1a :  Loading , cleaning and Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2202 entries, 0 to 2201\n",
      "Data columns (total 2 columns):\n",
      "Sentence    2202 non-null object\n",
      "Polarity    2202 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sentence    object\n",
       "Polarity     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Downloads/sentiment_train.csv\")\n",
    "df.info()\n",
    "df.head()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Sentence']\n",
    "y = df['Polarity']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1761,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1963    I use this product in a motor control center w...\n",
       "486     They had a toro tartare with a cavier that was...\n",
       "1192    Lately they have been extremely nice and helpf...\n",
       "755     When I'm on this side of town, this will defin...\n",
       "1680                 And none of the tones is acceptable.\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1761,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1963    1\n",
       "486     1\n",
       "1192    1\n",
       "755     1\n",
       "1680    0\n",
       "Name: Polarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)\n",
    "X_train.shape\n",
    "X_train.head()\n",
    "\n",
    "type(y_train)\n",
    "y_train.shape\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import unidecode\n",
    "import textstat\n",
    "import string  \n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def my_preprocess(doc):\n",
    "    \n",
    "    # Lowercase\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # Replace URL with URL string\n",
    "    doc = re.sub(r'http\\S+', 'URL', doc)\n",
    "    \n",
    "    # Replace AT with AT string\n",
    "    doc = re.sub(r'@', 'AT', doc)\n",
    "    \n",
    "    # Replace all numbers/digits with the string NUM\n",
    "    doc = re.sub(r'\\b\\d+\\b', 'NUM', doc)\n",
    "    \n",
    "    # Lemmatize each word.\n",
    "    doc = ' '.join([lemmer.lemmatize(w) for w in doc.split()])\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions will calculate additional features on the document.\n",
    "from textblob import TextBlob\n",
    "\n",
    "def doc_length(corpus):\n",
    "    return np.array([len(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def lexicon_count(corpus):\n",
    "    return np.array([textstat.lexicon_count(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def Sentiment_polarity(corpus):\n",
    "    return np.array([TextBlob(doc).sentiment.polarity for doc in corpus]).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1b : Feature Engineering\n",
    "custom features were engineered to check if they contribute to improving the model's classification value\n",
    "Extracting more featires using BOW, N-grams, vertorization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharg\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Need to preprocess the stopwords, because scikit learn's TfidfVectorizer\n",
    "# removes stopwords _after_ preprocessing\n",
    "stop_words = [my_preprocess(word) for word in stop_words.ENGLISH_STOP_WORDS]\n",
    "\n",
    "# This vectorizer will be used to create the BOW features\n",
    "vectorizer = TfidfVectorizer(preprocessor=my_preprocess, \n",
    "                             max_features = 1000, \n",
    "                             ngram_range=[1,3],\n",
    "                             stop_words=None,\n",
    "                             strip_accents=\"unicode\", \n",
    "                             lowercase=False, max_df=0.25, min_df=0.001, use_idf=True)\n",
    "\n",
    "# This vectorizer will be used to preprocess the text before topic modeling.\n",
    "# (I _could_ use the same vectorizer as above- but why limit myself?)\n",
    "vectorizer2 = TfidfVectorizer(preprocessor=my_preprocess, \n",
    "                             max_features =1000, \n",
    "                             ngram_range=[1,3],\n",
    "                             stop_words=None,\n",
    "                             strip_accents=\"unicode\", \n",
    "                             lowercase=False, max_df=0.25, min_df=0.001, use_idf=True)\n",
    "\n",
    "nmf = NMF(n_components= 35, random_state=1, init='nndsvda', solver='mu', alpha=.1, l1_ratio=.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "below Pipeline contains feature processing followed by modelling\n",
    "Model selection: Random Forest, Logistic Regression, MLP\n",
    "Data was then fit to each model and cross validation was performed for each model while also tuning hyperparameters for MLP and RF model. however for logistic regression there was no hyper parameter tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', random_state=225)\n",
    "lr= LogisticRegression(class_weight=True, random_state=123)\n",
    "mlp = MLPClassifier(random_state=42, verbose=2, max_iter=250)\n",
    "\n",
    "feature_processing =  FeatureUnion([ \n",
    "    ('bow', Pipeline([('cv', vectorizer), ])),\n",
    "    ('topics', Pipeline([('cv', vectorizer2), ('nmf', nmf),])),\n",
    "    ('length', FunctionTransformer(doc_length, validate=False)),\n",
    "    ('words', FunctionTransformer(lexicon_count, validate=False)),\n",
    "    ('Sentiment_polarity', FunctionTransformer(Sentiment_polarity, validate=False)),\n",
    "])\n",
    "\n",
    "steps = [('features', feature_processing)]\n",
    "\n",
    "pipe = Pipeline([('features', feature_processing), ('clf', rf)])\n",
    "\n",
    "param_grid = {}\n",
    "which_clf = \"lr\"\n",
    "\n",
    "if which_clf == \"RF\":\n",
    "\n",
    "    steps.append(('clf', rf))\n",
    "    param_grid = {\n",
    "        'features__bow__cv__preprocessor': [None, my_preprocess],\n",
    "        'features__bow__cv__max_features': [200, 500, 1000],\n",
    "        'features__bow__cv__use_idf': [False],\n",
    "        'features__topics__cv__stop_words': [None],\n",
    "        'features__topics__nmf__n_components': [25, 100],\n",
    "        'clf__n_estimators': [100, 1000],\n",
    "        'clf__class_weight': [None],\n",
    "    }\n",
    "    \n",
    "elif which_clf == \"MLP\":\n",
    "    \n",
    "    steps.append(('clf', mlp))\n",
    "    param_grid = {\n",
    "        'features__bow__cv__preprocessor': [my_preprocess],\n",
    "        'features__bow__cv__max_features': [1000, 3000],\n",
    "        'features__bow__cv__min_df': [0],\n",
    "        'features__bow__cv__use_idf': [False],\n",
    "        'features__topics__nmf__n_components': [100,300],\n",
    "        'clf__hidden_layer_sizes': [(100, ), (50, 50), (25, 25, 25)],\n",
    "    }\n",
    "\n",
    "elif which_clf == \"lr\":\n",
    "    steps.append(('clf', lr))\n",
    "    \n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=4, n_jobs=4, scoring='f1_micro', return_train_score=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    4.9s finished\n",
      "C:\\Users\\sharg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "search = search.fit(X_train, y_train)\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV scy_train0.806):\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV scy_train%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.562262</td>\n",
       "      <td>0.606038</td>\n",
       "      <td>0.870339</td>\n",
       "      <td>0.00376</td>\n",
       "      <td>0.805812</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_train_score  std_train_score  \\\n",
       "0       2.562262         0.606038          0.870339          0.00376   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.805812        0.023453                1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the results of hyperparmater tuning\n",
    "\n",
    "def cv_results_to_df(cv_results):\n",
    "    results = pd.DataFrame(list(cv_results['params']))\n",
    "    results['mean_fit_time'] = cv_results['mean_fit_time']\n",
    "    results['mean_score_time'] = cv_results['mean_score_time']\n",
    "    results['mean_train_score'] = cv_results['mean_train_score']\n",
    "    results['std_train_score'] = cv_results['std_train_score']\n",
    "    results['mean_test_score'] = cv_results['mean_test_score']\n",
    "    results['std_test_score'] = cv_results['std_test_score']\n",
    "    results['rank_test_score'] = cv_results['rank_test_score']\n",
    "\n",
    "    results = results.sort_values(['mean_test_score'], ascending=False)\n",
    "    return results\n",
    "\n",
    "results = cv_results_to_df(search.cv_results_)\n",
    "results\n",
    "#results.to_csv('results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Model performance on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we are using a pipeline and a GridSearchCV, things are a bit complicated.\n",
    "\n",
    "# The pipeline with the best performance\n",
    "pipeline = search.best_estimator_\n",
    "\n",
    "# Get the feature processing pipeline, so I can use it later\n",
    "feature_processing_obj = pipeline.named_steps['features']\n",
    "\n",
    "# Find the vectorizer objects, the NMF objects, and the classifier objects\n",
    "pipevect= dict(pipeline.named_steps['features'].transformer_list)\n",
    "vectorizer_obj = pipevect.get('bow').named_steps['cv']\n",
    "vectorizer_obj2 = pipevect.get('topics').named_steps['cv']\n",
    "nmf_obj = pipevect.get('topics').named_steps['nmf']\n",
    "clf_obj = pipeline.named_steps['clf']\n",
    "\n",
    "# Sanity check - what was vocabSize set to? Should match the output here.\n",
    "len(vectorizer_obj.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[199  28]\n",
      " [ 35 179]]\n",
      "\n",
      "F1 Score = 0.85714\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       227\n",
      "           1       0.86      0.84      0.85       214\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.86      0.86      0.86       441\n",
      "weighted avg       0.86      0.86      0.86       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "features_val = feature_processing_obj.transform(X_val).todense()\n",
    "\n",
    "pred_val = search.predict(X_val)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_val, pred_val))\n",
    "\n",
    "print(\"\\nF1 Score = {:.5f}\".format(f1_score(y_val, pred_val, average='micro')))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating model performance in Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[219  30]\n",
      " [ 92 205]]\n",
      "\n",
      "F1 Score = 0.77656\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78       249\n",
      "           1       0.87      0.69      0.77       297\n",
      "\n",
      "    accuracy                           0.78       546\n",
      "   macro avg       0.79      0.78      0.78       546\n",
      "weighted avg       0.80      0.78      0.78       546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('Downloads/sentiment_test.csv')\n",
    "\n",
    "features_test = feature_processing_obj.transform(test_df['Sentence']).todense()\n",
    "pred_test = search.predict(test_df['Sentence'])\n",
    "test_df = pd.read_csv('Downloads/sentiment_test.csv')\n",
    "\n",
    "features_test = feature_processing_obj.transform(test_df['Sentence']).todense()\n",
    "pred_test = search.predict(test_df['Sentence'])\n",
    "\n",
    "y_test = test_df['Polarity']\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred_test))\n",
    "\n",
    "print(\"\\nF1 Score = {:.5f}\".format(f1_score(y_test, pred_test, average=\"micro\")))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'Sentence': test_df.Sentence, 'Sentence_Polarity': test_df.Polarity,'predicted Polarity': pred_test})\n",
    "my_submission.to_csv('sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mis_classification Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence_Polarity</th>\n",
       "      <th>predicted Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A good commentary of today's love and undoubte...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>For people who are first timers in film making...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It was very popular when I was in the cinema, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>It has northern humour and positive about the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>I rather enjoyed it.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I liked it.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>I couldn't take them seriously.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>It really created a unique feeling though.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Vivian Schilling did an excellent job with the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>A world better than 95% of the garbage in the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Her role was played well.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Not too screamy not to masculine but just righ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>The camera really likes her in this movie.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>I would have casted her in that role after rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>As a European, the movie is a nice throwback t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>I am a fan of his ... This movie sucked really...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Even worse than Ticker!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>&amp; That movie was bad.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Only like 3 or 4 buildings used, a couple of l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>It just blew.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>This movie is excellent!Angel is beautiful and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>I just cant explain this movie more than roman...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Now we were chosen to be tortured with this di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>This show is made for Americans - it is too st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Almost everyone involved must be return to sch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>I wish I could enter negative values, admins?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>The sets are so bad, they wouldn't look out of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>The use of slow-motion needlessly repeats itse...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Oh yeah, and the storyline was pathetic too.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>I hate writing bad reviews about films - espec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>I am not a filmmaker nor am I a director but I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>In short - this was a monumental waste of time...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>It came free with a DVD player I bought but I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1/10 - and only because there is no setting fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>An interesting premise, and Billy Drago is alw...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>The soundtrack wasn't terrible, either.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>But the acting--even that of such professional...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Still, it was the SETS that got a big \"10\" on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Yes, I am simplifying things here for the sake...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Both do good jobs and are quite amusing.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>But the convoluted plot just didn't convince m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>I let my girlfriend talk me into seeing this -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>The last 15 minutes of movie are also not bad ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Bela Lugosi was totally extraneous, intoning o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>The acting was decidely wooden, though no wors...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>I like Armand Assante &amp; my cable company's sum...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>I believe the screenwriter did a good job of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>My 8/10 score is mostly for the plot.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>I won't say any more - I don't like spoilers, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  Sentence_Polarity  \\\n",
       "0   A good commentary of today's love and undoubte...                  1   \n",
       "1   For people who are first timers in film making...                  1   \n",
       "2   It was very popular when I was in the cinema, ...                  1   \n",
       "3   It's a feel-good film and that's how I felt wh...                  1   \n",
       "4   It has northern humour and positive about the ...                  1   \n",
       "5                              I rather enjoyed it.                    1   \n",
       "6                                       I liked it.                    1   \n",
       "7                   I couldn't take them seriously.                    0   \n",
       "8        It really created a unique feeling though.                    1   \n",
       "9   Vivian Schilling did an excellent job with the...                  1   \n",
       "10  A world better than 95% of the garbage in the ...                  1   \n",
       "11                        Her role was played well.                    1   \n",
       "12  Not too screamy not to masculine but just righ...                  1   \n",
       "13       The camera really likes her in this movie.                    1   \n",
       "14  I would have casted her in that role after rea...                  1   \n",
       "15  As a European, the movie is a nice throwback t...                  1   \n",
       "16  I am a fan of his ... This movie sucked really...                  0   \n",
       "17                          Even worse than Ticker!                    0   \n",
       "18                            & That movie was bad.                    0   \n",
       "19  Only like 3 or 4 buildings used, a couple of l...                  0   \n",
       "20                                    It just blew.                    0   \n",
       "21  This movie is excellent!Angel is beautiful and...                  1   \n",
       "22  I just cant explain this movie more than roman...                  1   \n",
       "23  Now we were chosen to be tortured with this di...                  0   \n",
       "24  This show is made for Americans - it is too st...                  0   \n",
       "25  Almost everyone involved must be return to sch...                  0   \n",
       "26    I wish I could enter negative values, admins?                    0   \n",
       "27  The sets are so bad, they wouldn't look out of...                  0   \n",
       "28  The use of slow-motion needlessly repeats itse...                  0   \n",
       "29     Oh yeah, and the storyline was pathetic too.                    0   \n",
       "30  I hate writing bad reviews about films - espec...                  0   \n",
       "31  I am not a filmmaker nor am I a director but I...                  0   \n",
       "32  In short - this was a monumental waste of time...                  0   \n",
       "33  It came free with a DVD player I bought but I ...                  0   \n",
       "34  1/10 - and only because there is no setting fo...                  0   \n",
       "35  An interesting premise, and Billy Drago is alw...                  1   \n",
       "36          The soundtrack wasn't terrible, either.                    1   \n",
       "37  But the acting--even that of such professional...                  0   \n",
       "38  Still, it was the SETS that got a big \"10\" on ...                  1   \n",
       "39  Yes, I am simplifying things here for the sake...                  0   \n",
       "40         Both do good jobs and are quite amusing.                    1   \n",
       "41  But the convoluted plot just didn't convince m...                  0   \n",
       "42  I let my girlfriend talk me into seeing this -...                  0   \n",
       "43  The last 15 minutes of movie are also not bad ...                  1   \n",
       "44  Bela Lugosi was totally extraneous, intoning o...                  0   \n",
       "45  The acting was decidely wooden, though no wors...                  0   \n",
       "46  I like Armand Assante & my cable company's sum...                  1   \n",
       "47  I believe the screenwriter did a good job of t...                  1   \n",
       "48            My 8/10 score is mostly for the plot.                    1   \n",
       "49  I won't say any more - I don't like spoilers, ...                  1   \n",
       "\n",
       "    predicted Polarity  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    0  \n",
       "8                    1  \n",
       "9                    1  \n",
       "10                   1  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   1  \n",
       "14                   0  \n",
       "15                   1  \n",
       "16                   0  \n",
       "17                   0  \n",
       "18                   0  \n",
       "19                   0  \n",
       "20                   0  \n",
       "21                   1  \n",
       "22                   1  \n",
       "23                   0  \n",
       "24                   0  \n",
       "25                   0  \n",
       "26                   0  \n",
       "27                   0  \n",
       "28                   0  \n",
       "29                   0  \n",
       "30                   0  \n",
       "31                   0  \n",
       "32                   0  \n",
       "33                   1  \n",
       "34                   0  \n",
       "35                   1  \n",
       "36                   0  \n",
       "37                   0  \n",
       "38                   0  \n",
       "39                   1  \n",
       "40                   1  \n",
       "41                   0  \n",
       "42                   0  \n",
       "43                   0  \n",
       "44                   0  \n",
       "45                   0  \n",
       "46                   1  \n",
       "47                   1  \n",
       "48                   1  \n",
       "49                   1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
